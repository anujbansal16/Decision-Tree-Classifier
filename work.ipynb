{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import necessary packages\n",
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read csv\n",
    "data=pd.read_csv(\"train.csv\")\n",
    "target='left'\n",
    "# data1=data.values\n",
    "# print(data)\n",
    "keyValueMap={ j:i for i,j in enumerate(list(data.columns.values))}\n",
    "features=[feature for feature in list(data.columns.values) if feature!=target]\n",
    "# cFeatures=['Work_accident','promotion_last_5years','sales','salary','satisfaction_level','last_evaluation','number_project','average_montly_hours','time_spend_company']\n",
    "cFeatures=['Work_accident','promotion_last_5years','sales','salary']\n",
    "nFeatures=['satisfaction_level','last_evaluation','number_project','average_montly_hours','time_spend_company']\n",
    "# print(len(data.where(data[nFeatures[0]]<=0.46).dropna()))\n",
    "# nFeatures=['satisfaction_level','last_evaluation','number_project','average_montly_hours','time_spend_company']\n",
    "# print([(feature,np.unique(data[feature])) for feature in features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def intrinsicCal(q):\n",
    "    if q:\n",
    "        return -q*np.log2(q)\n",
    "    return 0\n",
    "\n",
    "def entropy(q):\n",
    "    if q>=1 or q<=0:\n",
    "        return 0\n",
    "    return -(q*np.log2(q)+(1-q)*np.log2(1-q))\n",
    "def gini(q):\n",
    "    return 2*q*(1-q)\n",
    "def misClass(q):\n",
    "    return min(q,1-q)\n",
    "entropy(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.020887530533461263\n"
     ]
    }
   ],
   "source": [
    "#return the information gain of current Attribute with impurity type(entrop/gini/misclass) relative to target attribute\n",
    "def infoGain(data,currentAttr,impType,targetAttr=\"left\"):\n",
    "    totalRows=data.shape[0]    \n",
    "    targetValues, targetValuesCount=np.unique(data[targetAttr],return_counts=True)\n",
    "    currentValues, currentValuesCount=np.unique(data[currentAttr],return_counts=True)\n",
    "    targetEntropy=impType(targetValuesCount[0]/(totalRows))\n",
    "    #(Si/S)*(entropy(target(=0)/Si)),(Si/S)*(entropy(target(=1)/Si)),.......\n",
    "    weightedEntropy=0\n",
    "    intrinsic=0\n",
    "    #(Si/S)*(entropy(target(=0)/Si)),(Sj/S)*(entropy(target(=0)/Sj)),.......\n",
    "    data1=data.values\n",
    "    valueMap={ j:0 for j in currentValues}\n",
    "    i=0\n",
    "    while(i<totalRows):\n",
    "        if data1[i][keyValueMap[targetAttr]]==0:\n",
    "            valueMap[data1[i][keyValueMap[currentAttr]]]+=1\n",
    "        i+=1\n",
    "    for j,i in enumerate(currentValues):\n",
    "        weightedEntropy+= ((currentValuesCount[j]/totalRows)*impType(valueMap[i]/currentValuesCount[j]))\n",
    "#     for j,i in enumerate(currentValues):\n",
    "#         weightedEntropy+= ((currentValuesCount[j]/totalRows)*impType(np.unique(data.where(data[currentAttr]==i).dropna()[targetAttr],return_counts=True)[1][0]/currentValuesCount[j]))\n",
    "#         intrinsic+=intrinsicCal(currentValuesCount[j]/totalRows)\n",
    "    informationGain=targetEntropy-weightedEntropy\n",
    "    return informationGain#/intrinsic\n",
    "print(infoGain(data,'salary',entropy))\n",
    "# print(infoGain(data,'promotion_last_5years',entropy))\n",
    "# print(infoGain(data,'Work_accident',entropy))\n",
    "# print(np.max([infoGain(data,feature,entropy) for feature in cFeatures]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.46"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def numericSplitInfoGain1(data,currentAttr, impType,targetAttr=\"left\" ):\n",
    "#     print(numericValue)\n",
    "    totalRows=data.shape[0]\n",
    "    currentAttrCol=data[currentAttr]\n",
    "#     print(totalRows)\n",
    "    targetValues, targetValuesCount=np.unique(data[targetAttr],return_counts=True)\n",
    "    targetEntropy=impType(targetValuesCount[0]/(totalRows))\n",
    "    numericValues=[] #all numberic values\n",
    "    informationGains=[] #for all unique numeric values in data\n",
    "    for numericValue in np.unique(data[currentAttr]):\n",
    "#         print(numericValue)\n",
    "        numericValues.append(numericValue)\n",
    "        values1,lableCountsForLess=np.unique(data.where(currentAttrCol<=numericValue).dropna()[targetAttr],return_counts=True)\n",
    "        values2,labelCountsForGreater=np.unique(data.where(currentAttrCol>numericValue).dropna()[targetAttr],return_counts=True)\n",
    "        recordsLessThanNumeric=np.sum(lableCountsForLess)\n",
    "        recordsGreaterThanNumeric=np.sum(labelCountsForGreater)\n",
    "#         print(numericValue,lableCountsForLess,labelCountsForGreater)\n",
    "        a=0\n",
    "        b=0\n",
    "        intrinsic=0\n",
    "        if recordsLessThanNumeric:\n",
    "            a=(recordsLessThanNumeric/totalRows)*impType(lableCountsForLess[0]/recordsLessThanNumeric)\n",
    "            intrinsic+=intrinsicCal(recordsLessThanNumeric/totalRows)\n",
    "        if recordsGreaterThanNumeric:\n",
    "            b=(recordsGreaterThanNumeric/totalRows)*impType(labelCountsForGreater[0]/recordsGreaterThanNumeric)\n",
    "            intrinsic+=intrinsicCal(recordsGreaterThanNumeric/totalRows)\n",
    "        weightedEntropy=a+b\n",
    "        informationGain=targetEntropy-weightedEntropy\n",
    "        informationGains.append(informationGain)\n",
    "#     print(targetEntropy)\n",
    "#     print(informationGain)\n",
    "    return numericValues[np.argmax(informationGains)]\n",
    "    \n",
    "# data=data.sort_values(by=\"satisfaction_level\", ascending=True, inplace=False)    \n",
    "# s=np.unique(data['satisfaction_level'])\n",
    "# s[np.argmax([numericSplitInfoGain(data,'satisfaction_level',value,entropy) for value in s ])]\n",
    "numericSplitInfoGain1(data,'satisfaction_level',entropy)\n",
    "# numericSplitInfoGain(data,'satisfaction_level',0.89,entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.46, 0.19312998759326316)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def numericSplitInfoGain(data,currentAttr, impType,target=\"left\"):\n",
    "    totalRows=data.shape[0]\n",
    "    data=data.sort_values(by=currentAttr, ascending=True, inplace=False)    \n",
    "    data1=data.values;\n",
    "    ones=np.sum(data[target])\n",
    "    zeros=totalRows-ones\n",
    "    targetEntropy=impType(ones/(totalRows))\n",
    "    lableCountsForLess=[0,0]\n",
    "    labelCountsForGreater=[0,0]\n",
    "    key=0\n",
    "    mx=-1\n",
    "    i=0\n",
    "    currentIndex=keyValueMap[currentAttr]\n",
    "    targetIndex=keyValueMap[target]\n",
    "    while i<totalRows:\n",
    "        numericValue=data1[i][currentIndex]\n",
    "        tl=data1[i][targetIndex]\n",
    "        if tl==0:\n",
    "            #count of zeros for currentAttr<=numericaval\n",
    "            lableCountsForLess[0]+=1\n",
    "        else:\n",
    "            lableCountsForLess[1]+=1\n",
    "        \n",
    "        #count of zeros for currentAttr>numericaval\n",
    "        labelCountsForGreater[0]=zeros-lableCountsForLess[0]\n",
    "        labelCountsForGreater[1]=ones-lableCountsForLess[1]\n",
    "        \n",
    "        if(i+1!=totalRows and data1[i+1][currentIndex]==numericValue):\n",
    "            i+=1\n",
    "            continue\n",
    "\n",
    "        recordsLessThanNumeric=np.sum(lableCountsForLess)\n",
    "        recordsGreaterThanNumeric=np.sum(labelCountsForGreater)\n",
    "        a=0\n",
    "        b=0\n",
    "        intrinsic=0\n",
    "        if recordsLessThanNumeric:\n",
    "            a=(recordsLessThanNumeric/totalRows)*impType(lableCountsForLess[0]/recordsLessThanNumeric)\n",
    "            intrinsic+=intrinsicCal(recordsLessThanNumeric/totalRows)\n",
    "        if recordsGreaterThanNumeric:\n",
    "            b=(recordsGreaterThanNumeric/totalRows)*impType(labelCountsForGreater[0]/recordsGreaterThanNumeric)\n",
    "            intrinsic+=intrinsicCal(recordsGreaterThanNumeric/totalRows)\n",
    "        weightedEntropy=a+b\n",
    "        informationGain=(targetEntropy-weightedEntropy)\n",
    "        if(informationGain>=mx):\n",
    "            mx=informationGain\n",
    "            key=numericValue\n",
    "        i+=1\n",
    "    return (key,mx)\n",
    "numericSplitInfoGain(data,nFeatures[0],entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('salary', 0.020887530533461263)"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def bestInfoGainFeature(data,cFeatures,impType,targetAttr=\"left\"):\n",
    "    #info gains for categorical attributes    \n",
    "    infGains=[infoGain(data,feature,impType) for feature in cFeatures]\n",
    "    featureIndex=np.argmax(infGains)\n",
    "    bestFeature=cFeatures[featureIndex]\n",
    "    return (bestFeature,infGains[featureIndex])\n",
    "bestInfoGainFeature(data,cFeatures,entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('satisfaction_level', 0.46, 0.19312998759326316)"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def bestInfoGainFeNumeric(data,impType):\n",
    "    mxinFo=0\n",
    "    split=0\n",
    "    resF=\"\"\n",
    "    for feature in nFeatures:\n",
    "        fInfoG=numericSplitInfoGain(data,feature,impType)\n",
    "#         print(\"finfo \",feature,fInfoG)\n",
    "        if fInfoG[1]>=mxinFo:\n",
    "            resF=feature\n",
    "            split=fInfoG[0]\n",
    "            mxinFo=fInfoG[1]\n",
    "    return (resF,split,mxinFo)\n",
    "bestInfoGainFeNumeric(data,entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def buildTree1(filterdData,cFeatures,targetAttr=\"left\"):\n",
    "    #check if data is pure i.e all tuples have exact 1 type of label\n",
    "    if(len(np.unique(filterdData[targetAttr]))<=1):\n",
    "        return np.unique(filterdData[targetAttr])[0]\n",
    "    #check if all the categorical attributes had been used\n",
    "    elif(len(cFeatures)==0):\n",
    "        values,count=np.unique(filterdData[targetAttr],return_counts=True)\n",
    "        return values[np.argmax(count)]\n",
    "    #else grow the tree for all possible value of best feature\n",
    "    #threby filtering the data on that value of best feature\n",
    "    else:\n",
    "        #find best feature\n",
    "        #remove best feature from local list of features(cFeatures) for now\n",
    "        #create a node with best feature and return it at the end\n",
    "        #execute a for loop for all possible value of best feature (filtering on this value), and create a branch on\n",
    "            #this value [best][value1] and receive the result of recursive call on this filtered data      \n",
    "        bestF=bestInfoGainFeature(filterdData,cFeatures, entropy)[0]\n",
    "#         print(bestF)\n",
    "        node={bestF:{}}\n",
    "        cFeatures=[feature for feature in cFeatures if feature!=bestF]\n",
    "        for value in np.unique(filterdData[bestF]):\n",
    "            #filter new datatable based on best feature [value]\n",
    "            filteredData=filterdData.where(filterdData[bestF]==value).dropna()\n",
    "            node[bestF][value]=buildTree1(filteredData,cFeatures)\n",
    "        \n",
    "    return node\n",
    "    \n",
    "# tree=buildTree1(data,cFeatures)\n",
    "# print(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'satisfaction_level': {(0.46, True): {'satisfaction_level': {(0.11, True): 1.0, (0.11, False): {'number_project': {(2.0, True): {'last_evaluation': {(0.57, True): {'last_evaluation': {(0.44, True): 0.0, (0.44, False): {'average_montly_hours': {(161.0, True): {'average_montly_hours': {(125.0, True): 0.0, (125.0, False): {'satisfaction_level': {(0.31, True): 0.0, (0.31, False): {'salary': {'high': {'sales': {'IT': 0.0, 'RandD': 0, 'accounting': 0, 'hr': 0, 'marketing': 0, 'product_mng': 0, 'sales': 0, 'support': 0, 'technical': 0}}, 'low': 0, 'medium': 0}}}}}}, (161.0, False): {'average_montly_hours': {(239.0, True): 0.0, (239.0, False): {'sales': {'IT': 0.0, 'sales': 0, 'support': 0, 'technical': 0}}}}}}}}, (0.57, False): {'sales': {'IT': 0.0, 'RandD': 0, 'accounting': 0, 'hr': 0, 'management': 0, 'marketing': 0, 'product_mng': 0, 'sales': 0, 'support': 0, 'technical': 0}}}}, (2.0, False): {'number_project': {(6.0, True): {'average_montly_hours': {(287.0, True): {'sales': {'IT': {'satisfaction_level': {(0.14, True): {'salary': {'low': 0.0, 'medium': 0}}, (0.14, False): 0.0}}, 'RandD': 0, 'accounting': 0, 'hr': 0, 'management': 0, 'marketing': 0, 'product_mng': 0, 'sales': 0, 'support': 0, 'technical': 0}}, (287.0, False): 1.0}}, (6.0, False): 1.0}}}}}}, (0.46, False): {'time_spend_company': {(4.0, True): {'average_montly_hours': {(287.0, True): {'number_project': {(5.0, True): {'time_spend_company': {(3.0, True): {'number_project': {(2.0, True): {'average_montly_hours': {(167.0, True): 0.0, (167.0, False): {'sales': {'IT': {'average_montly_hours': {(273.0, True): 0.0, (273.0, False): 1.0}}, 'RandD': 0, 'accounting': 0, 'hr': 0, 'management': 0, 'marketing': 0, 'product_mng': 0, 'sales': 0, 'support': 0, 'technical': 0}}}}, (2.0, False): {'sales': {'IT': 0.0, 'RandD': 0, 'accounting': 0, 'hr': 0, 'management': 0, 'marketing': 0, 'product_mng': 0, 'sales': 0, 'support': 0, 'technical': 0}}}}, (3.0, False): {'sales': {'IT': 0.0, 'RandD': 0, 'accounting': 0, 'hr': 0, 'management': 0, 'marketing': 0, 'product_mng': 0, 'sales': 0, 'support': 0, 'technical': 0}}}}, (5.0, False): {'sales': {'IT': {'average_montly_hours': {(161.0, True): {'average_montly_hours': {(118.0, True): 0.0, (118.0, False): 1.0}}, (161.0, False): 0.0}}, 'RandD': 0, 'accounting': 0, 'hr': 0, 'management': 0, 'marketing': 0, 'product_mng': 0, 'sales': 0, 'support': 0, 'technical': 0}}}}, (287.0, False): 1.0}}, (4.0, False): {'last_evaluation': {(0.8, True): {'sales': {'IT': {'average_montly_hours': {(166.0, True): {'average_montly_hours': {(163.0, True): {'last_evaluation': {(0.73, True): 0.0, (0.73, False): 1.0}}, (163.0, False): 1.0}}, (166.0, False): 0.0}}, 'RandD': 0, 'accounting': 0, 'hr': 0, 'management': 0, 'marketing': 0, 'product_mng': 0, 'sales': 0, 'support': 0, 'technical': 0}}, (0.8, False): {'average_montly_hours': {(216.0, True): {'time_spend_company': {(5.0, True): {'number_project': {(3.0, True): {'average_montly_hours': {(138.0, True): 0.0, (138.0, False): {'salary': {'low': {'sales': {'hr': 1.0, 'product_mng': 0, 'sales': 0, 'support': 0, 'technical': 0}}, 'medium': 0}}}}, (3.0, False): 0.0}}, (5.0, False): {'last_evaluation': {(0.99, True): {'number_project': {(5.0, True): 0.0, (5.0, False): {'sales': {'accounting': 0.0, 'product_mng': 0, 'sales': 0, 'support': 0, 'technical': 0}}}}, (0.99, False): 1.0}}}}, (216.0, False): {'time_spend_company': {(6.0, True): {'satisfaction_level': {(0.71, True): {'last_evaluation': {(0.91, True): {'sales': {'IT': 0.0, 'RandD': 0, 'accounting': 0, 'management': 0, 'marketing': 0, 'product_mng': 0, 'sales': 0, 'support': 0, 'technical': 0}}, (0.91, False): {'sales': {'IT': 0.0, 'RandD': 0, 'marketing': 0, 'product_mng': 0, 'sales': 0, 'technical': 0}}}}, (0.71, False): {'number_project': {(3.0, True): {'average_montly_hours': {(286.0, True): 0.0, (286.0, False): 1.0}}, (3.0, False): {'number_project': {(5.0, True): {'satisfaction_level': {(0.92, True): {'sales': {'IT': 1.0, 'RandD': 0, 'accounting': 0, 'hr': 0, 'management': 0, 'marketing': 0, 'product_mng': 0, 'sales': 0, 'support': 0, 'technical': 0}}, (0.92, False): 0.0}}, (5.0, False): 0.0}}}}}}, (6.0, False): 0.0}}}}}}}}}}\n"
     ]
    }
   ],
   "source": [
    "def buildTree(filteredData,odata,cFeatures,targetAttr=\"left\"):\n",
    "    if len(filteredData)==0:\n",
    "        values,count=np.unique(odata[targetAttr],return_counts=True)\n",
    "        return values[np.argmax(count)]\n",
    "    #check if data is pure i.e all tuples have exact 1 type of label\n",
    "    if(len(np.unique(filteredData[targetAttr]))==1):\n",
    "        return np.unique(filteredData[targetAttr])[0]\n",
    "    #check if all the categorical attributes had been used\n",
    "    elif(len(cFeatures)==0):\n",
    "            bestFNum=bestInfoGainFeNumeric(filteredData, entropy)\n",
    "            bestF=bestFNum[0]\n",
    "            split=bestFNum[1]\n",
    "            ig=bestFNum[2]\n",
    "            if ig<=0.00000001:\n",
    "                values,count=np.unique(filteredData[targetAttr],return_counts=True)\n",
    "                return values[np.argmax(count)]\n",
    "            node={bestF:{}}\n",
    "            node[bestF][(split,True)]=buildTree(filteredData.where(filteredData[bestF]<=split).dropna(),odata,cFeatures)\n",
    "            node[bestF][(split,False)]=buildTree(filteredData.where(filteredData[bestF]>split).dropna(),odata,cFeatures)\n",
    "            return node;\n",
    "    else:\n",
    "        bestFCate=bestInfoGainFeature(filteredData,cFeatures, entropy)\n",
    "        bestFNum=bestInfoGainFeNumeric(filteredData, entropy)\n",
    "        isCat=False\n",
    "        if bestFCate[1]>=bestFNum[2]:\n",
    "            isCat=True\n",
    "        if isCat:\n",
    "            bestF=bestFCate[0]\n",
    "            node={bestF:{}}\n",
    "            cFeatures=[feature for feature in cFeatures if feature!=bestF]\n",
    "            for value in np.unique(filteredData[bestF]):\n",
    "                #filter new datatable based on best feature [value]\n",
    "                filteredData=filteredData.where(filteredData[bestF]==value).dropna()\n",
    "                node[bestF][value]=buildTree(filteredData,odata,cFeatures)\n",
    "        else:\n",
    "            bestF=bestFNum[0]\n",
    "            split=bestFNum[1]\n",
    "            node={bestF:{}}\n",
    "            node[bestF][(split,True)]=buildTree(filteredData.where(filteredData[bestF]<=split).dropna(),odata,cFeatures)\n",
    "            node[bestF][(split,False)]=buildTree(filteredData.where(filteredData[bestF]>split).dropna(),odata,cFeatures)\n",
    "        \n",
    "    return node\n",
    "    \n",
    "tree=buildTree(data,data,cFeatures)\n",
    "print(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'salary': {'high': {'sales': {'IT': {'Work_accident': {0.0: {'promotion_last_5years': {0.0: 0.0}}, 1.0: 0.0}}, 'RandD': {'Work_accident': {0.0: {'promotion_last_5years': {0.0: 0.0, 1.0: 0.0}}, 1.0: 0.0}}, 'accounting': {'Work_accident': {0.0: {'promotion_last_5years': {0.0: 0.0, 1.0: 0.0}}, 1.0: 0.0}}, 'hr': {'Work_accident': {0.0: {'promotion_last_5years': {0.0: 0.0, 1.0: 0.0}}, 1.0: 0.0}}, 'management': {'promotion_last_5years': {0.0: {'Work_accident': {0.0: 0.0, 1.0: 0.0}}, 1.0: 0.0}}, 'marketing': {'Work_accident': {0.0: {'promotion_last_5years': {0.0: 0.0, 1.0: 0.0}}, 1.0: 0.0}}, 'product_mng': {'Work_accident': {0.0: {'promotion_last_5years': {0.0: 0.0}}, 1.0: 0.0}}, 'sales': {'Work_accident': {0.0: {'promotion_last_5years': {0.0: 0.0, 1.0: 0.0}}, 1.0: 0.0}}, 'support': {'Work_accident': {0.0: {'promotion_last_5years': {0.0: 0.0}}, 1.0: 0.0}}, 'technical': {'Work_accident': {0.0: {'promotion_last_5years': {0.0: 0.0}}, 1.0: 0.0}}}}, 'low': {'Work_accident': {0.0: {'sales': {'IT': {'promotion_last_5years': {0.0: 0.0, 1.0: 1.0}}, 'RandD': {'promotion_last_5years': {0.0: 0.0, 1.0: 0.0}}, 'accounting': {'promotion_last_5years': {0.0: 0.0, 1.0: 0.0}}, 'hr': {'promotion_last_5years': {0.0: 0.0, 1.0: 0.0}}, 'management': {'promotion_last_5years': {0.0: 0.0, 1.0: 1.0}}, 'marketing': {'promotion_last_5years': {0.0: 0.0, 1.0: 0.0}}, 'product_mng': {'promotion_last_5years': {0.0: 0.0}}, 'sales': {'promotion_last_5years': {0.0: 0.0, 1.0: 0.0}}, 'support': {'promotion_last_5years': {0.0: 0.0, 1.0: 0.0}}, 'technical': {'promotion_last_5years': {0.0: 0.0, 1.0: 0.0}}}}, 1.0: {'sales': {'IT': {'promotion_last_5years': {0.0: 0.0}}, 'RandD': {'promotion_last_5years': {0.0: 0.0, 1.0: 0.0}}, 'accounting': {'promotion_last_5years': {0.0: 0.0}}, 'hr': {'promotion_last_5years': {0.0: 0.0}}, 'management': {'promotion_last_5years': {0.0: 0.0, 1.0: 0.0}}, 'marketing': {'promotion_last_5years': {0.0: 0.0, 1.0: 0.0}}, 'product_mng': {'promotion_last_5years': {0.0: 0.0}}, 'sales': {'promotion_last_5years': {0.0: 0.0, 1.0: 1.0}}, 'support': {'promotion_last_5years': {0.0: 0.0}}, 'technical': {'promotion_last_5years': {0.0: 0.0, 1.0: 0.0}}}}}}, 'medium': {'Work_accident': {0.0: {'sales': {'IT': {'promotion_last_5years': {0.0: 0.0, 1.0: 1.0}}, 'RandD': {'promotion_last_5years': {0.0: 0.0, 1.0: 0.0}}, 'accounting': {'promotion_last_5years': {0.0: 0.0, 1.0: 0.0}}, 'hr': {'promotion_last_5years': {0.0: 0.0, 1.0: 0.0}}, 'management': {'promotion_last_5years': {0.0: 0.0, 1.0: 0.0}}, 'marketing': {'promotion_last_5years': {0.0: 0.0, 1.0: 0.0}}, 'product_mng': {'promotion_last_5years': {0.0: 0.0}}, 'sales': {'promotion_last_5years': {0.0: 0.0, 1.0: 0.0}}, 'support': {'promotion_last_5years': {0.0: 0.0, 1.0: 0.0}}, 'technical': {'promotion_last_5years': {0.0: 0.0, 1.0: 0.0}}}}, 1.0: {'sales': {'IT': {'promotion_last_5years': {0.0: 0.0}}, 'RandD': {'promotion_last_5years': {0.0: 0.0, 1.0: 0.0}}, 'accounting': {'promotion_last_5years': {0.0: 0.0}}, 'hr': {'promotion_last_5years': {0.0: 0.0, 1.0: 0.0}}, 'management': {'promotion_last_5years': {0.0: 0.0, 1.0: 0.0}}, 'marketing': {'promotion_last_5years': {0.0: 0.0, 1.0: 0.0}}, 'product_mng': {'promotion_last_5years': {0.0: 0.0}}, 'sales': {'promotion_last_5years': {0.0: 0.0, 1.0: 0.0}}, 'support': {'promotion_last_5years': {0.0: 0.0, 1.0: 0.0}}, 'technical': {'promotion_last_5years': {0.0: 0.0, 1.0: 0.0}}}}}}}}\n"
     ]
    }
   ],
   "source": [
    "totalDataSets=len(data)\n",
    "trainDataPercent=100\n",
    "trainDataSetCount=int(trainDataPercent*totalDataSets/100)\n",
    "\n",
    "trainData=data[:trainDataSetCount]\n",
    "validateData=trainData\n",
    "# validateData=data[trainDataSetCount:]\n",
    "tree=buildTree1(trainData,cFeatures)\n",
    "print(tree)\n",
    "# print(\"finish\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76.24132407901762\n"
     ]
    }
   ],
   "source": [
    "def predictClass(tree,validateDataRow):\n",
    "    dataCols=validateDataRow.keys()\n",
    "    for key in dataCols:\n",
    "        if key in tree.keys():\n",
    "            try:\n",
    "                temp=tree[key][validateDataRow[key]]\n",
    "            except:\n",
    "                return 0\n",
    "            if isinstance(temp,dict):\n",
    "                return predictClass(temp,validateDataRow)\n",
    "            else:\n",
    "                return temp   \n",
    "count=0\n",
    "validateData1=validateData.to_dict(orient = \"records\")\n",
    "for i in range(len(validateData1)):\n",
    "    if validateData.iloc[i][keyValueMap[\"left\"]]==predictClass(tree,validateData1[i]):\n",
    "        count+=1\n",
    "print(count*100/len(validateData))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
