{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import necessary packages\n",
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read csv\n",
    "data=pd.read_csv(\"train.csv\")\n",
    "target='left'\n",
    "keyValueMap={ j:i for i,j in enumerate(list(data.columns.values))}\n",
    "features=[feature for feature in list(data.columns.values) if feature!=target]\n",
    "cFeatures=['Work_accident','promotion_last_5years','sales','salary']\n",
    "nFeatures=['satisfaction_level','last_evaluation','number_project','average_montly_hours','time_spend_company']\n",
    "# nFeatures=['satisfaction_level','last_evaluation','number_project','average_montly_hours','time_spend_company']\n",
    "# print([(feature,np.unique(data[feature])) for feature in features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intrinsicCal(q):\n",
    "    if q:\n",
    "        return -q*np.log2(q)\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def entropy(q):\n",
    "    if q>=1 or q<=0:\n",
    "        return 0\n",
    "    return -(q*np.log2(q)+(1-q)*np.log2(1-q))\n",
    "entropy(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gini(q):\n",
    "    return 2*q*(1-q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def misClass(q):\n",
    "    return min(q,1-q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.020887530533461263\n"
     ]
    }
   ],
   "source": [
    "#return the information gain of current Attribute with impurity type(entrop/gini/misclass) relative to target attribute\n",
    "def infoGain(data,currentAttr,impType,targetAttr=\"left\"):\n",
    "    totalRows=data.shape[0]    \n",
    "    targetValues, targetValuesCount=np.unique(data[targetAttr],return_counts=True)\n",
    "    currentValues, currentValuesCount=np.unique(data[currentAttr],return_counts=True)\n",
    "    targetEntropy=impType(targetValuesCount[0]/(totalRows))\n",
    "    weightedEntropy=0\n",
    "    intrinsic=0\n",
    "    data1=data.values\n",
    "    valueMap={ j:0 for j in currentValues}\n",
    "    i=0\n",
    "    while(i<totalRows):\n",
    "        if data1[i][keyValueMap[targetAttr]]==0:\n",
    "            valueMap[data1[i][keyValueMap[currentAttr]]]+=1\n",
    "        i+=1\n",
    "        \n",
    "    #(Si/S)*(entropy(target(=0)/Si)),(Sj/S)*(entropy(target(=0)/Sj)),.......\n",
    "    for j,i in enumerate(currentValues):\n",
    "        weightedEntropy+= ((currentValuesCount[j]/totalRows)*impType(valueMap[i]/currentValuesCount[j]))\n",
    "        intrinsic+=intrinsicCal(currentValuesCount[j]/totalRows)\n",
    "        \n",
    "    informationGain=targetEntropy-weightedEntropy\n",
    "    return informationGain#/intrinsic\n",
    "\n",
    "print(infoGain(data,'salary',entropy))\n",
    "# print(infoGain(data,'promotion_last_5years',entropy))\n",
    "# print(infoGain(data,'Work_accident',entropy))\n",
    "# print(np.max([infoGain(data,feature,entropy) for feature in cFeatures]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.46, 0.19312998759326316)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def numericSplitInfoGain(data,currentAttr, impType,target=\"left\"):\n",
    "    totalRows=data.shape[0]\n",
    "    data=data.sort_values(by=currentAttr, ascending=True, inplace=False)    \n",
    "    data1=data.values;\n",
    "    ones=np.sum(data[target])\n",
    "    zeros=totalRows-ones\n",
    "    targetEntropy=impType(ones/(totalRows))\n",
    "    lableCountsForLess=[0,0]\n",
    "    labelCountsForGreater=[0,0]\n",
    "    key=0\n",
    "    mx=-1\n",
    "    i=0\n",
    "    currentIndex=keyValueMap[currentAttr]\n",
    "    targetIndex=keyValueMap[target]\n",
    "    while i<totalRows:\n",
    "        numericValue=data1[i][currentIndex]\n",
    "        tl=data1[i][targetIndex]\n",
    "        if tl==0:\n",
    "            #count of zeros for currentAttr<=numericaval\n",
    "            lableCountsForLess[0]+=1\n",
    "        else:\n",
    "            lableCountsForLess[1]+=1\n",
    "        \n",
    "        #count of zeros for currentAttr>numericaval\n",
    "        labelCountsForGreater[0]=zeros-lableCountsForLess[0]\n",
    "        labelCountsForGreater[1]=ones-lableCountsForLess[1]\n",
    "        \n",
    "        if(i+1!=totalRows and data1[i+1][currentIndex]==numericValue):\n",
    "            i+=1\n",
    "            continue\n",
    "\n",
    "        recordsLessThanNumeric=np.sum(lableCountsForLess)\n",
    "        recordsGreaterThanNumeric=np.sum(labelCountsForGreater)\n",
    "        a=0\n",
    "        b=0\n",
    "        intrinsic=0\n",
    "        if recordsLessThanNumeric:\n",
    "            a=(recordsLessThanNumeric/totalRows)*impType(lableCountsForLess[0]/recordsLessThanNumeric)\n",
    "            intrinsic+=intrinsicCal(recordsLessThanNumeric/totalRows)\n",
    "        if recordsGreaterThanNumeric:\n",
    "            b=(recordsGreaterThanNumeric/totalRows)*impType(labelCountsForGreater[0]/recordsGreaterThanNumeric)\n",
    "            intrinsic+=intrinsicCal(recordsGreaterThanNumeric/totalRows)\n",
    "        weightedEntropy=a+b\n",
    "        informationGain=(targetEntropy-weightedEntropy)\n",
    "        if(informationGain>=mx):\n",
    "            mx=informationGain\n",
    "            key=numericValue\n",
    "        i+=1\n",
    "    return (key,mx)\n",
    "numericSplitInfoGain(data,nFeatures[0],entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('salary', 0.020887530533461263)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def bestInfoGainFeature(data,cFeatures,impType,targetAttr=\"left\"):\n",
    "    #info gains for categorical attributes    \n",
    "    infGains=[infoGain(data,feature,impType) for feature in cFeatures]\n",
    "    featureIndex=np.argmax(infGains)\n",
    "    bestFeature=cFeatures[featureIndex]\n",
    "    return (bestFeature,infGains[featureIndex])\n",
    "\n",
    "bestInfoGainFeature(data,cFeatures,entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('satisfaction_level', 0.46, 0.19312998759326316)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def bestInfoGainFeNumeric(data,impType):\n",
    "    mxinFo=0\n",
    "    split=0\n",
    "    resF=\"\"\n",
    "    for feature in nFeatures:\n",
    "        fInfoG=numericSplitInfoGain(data,feature,impType)\n",
    "        if fInfoG[1]>=mxinFo:\n",
    "            resF=feature\n",
    "            split=fInfoG[0]\n",
    "            mxinFo=fInfoG[1]\n",
    "    return (resF,split,mxinFo)\n",
    "bestInfoGainFeNumeric(data,entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def buildTree1(filterdData,cFeatures,targetAttr=\"left\"):\n",
    "    \n",
    "    #check if data is pure i.e all tuples have exact 1 type of label\n",
    "    if(len(np.unique(filterdData[targetAttr]))<=1):\n",
    "        return np.unique(filterdData[targetAttr])[0]\n",
    "    \n",
    "    #check if all the categorical attributes had been used\n",
    "    elif(len(cFeatures)==0):\n",
    "        values,count=np.unique(filterdData[targetAttr],return_counts=True)\n",
    "        return values[np.argmax(count)]\n",
    "    \n",
    "    #else grow the tree for all possible value of best feature\n",
    "    #threby filtering the data on that value of best feature\n",
    "    else:\n",
    "        #find best feature\n",
    "        #create a node with best feature and return it at the end\n",
    "        #remove best feature from local list of features(cFeatures) for now\n",
    "        #execute a for loop for all possible value of best feature (filtering on this value), and create a branch on\n",
    "            #this value [best][value1] and receive the result of recursive call on this filtered data      \n",
    "        bestF=bestInfoGainFeature(filterdData,cFeatures, entropy)[0]\n",
    "        node={bestF:{}}\n",
    "        cFeatures=[feature for feature in cFeatures if feature!=bestF]\n",
    "        for value in np.unique(filterdData[bestF]):\n",
    "            #filter new datatable based on best feature [value]\n",
    "            filteredData=filterdData.where(filterdData[bestF]==value).dropna()\n",
    "            node[bestF][value]=buildTree1(filteredData,cFeatures)\n",
    "        \n",
    "    return node\n",
    "    \n",
    "# tree=buildTree1(data,cFeatures)\n",
    "# print(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def buildTree(filteredData,odata,cFeatures,parent_node_class=None,targetAttr=\"left\"):\n",
    "    #check if data is empty if so return the mode of \"left\" label appeared in its parent data\n",
    "    if len(filteredData)==0:\n",
    "        return parent_node_class\n",
    "    \n",
    "    #check if data is pure i.e all tuples have exact 1 type of label\n",
    "    if(len(np.unique(filteredData[targetAttr]))==1):\n",
    "        return np.unique(filteredData[targetAttr])[0]\n",
    "    \n",
    "    #check if all the categorical attributes had been used (numerical split may be possible)\n",
    "    elif(len(cFeatures)==0):\n",
    "            bestFNum=bestInfoGainFeNumeric(filteredData, entropy)\n",
    "            bestF=bestFNum[0]\n",
    "            split=bestFNum[1]\n",
    "            ig=bestFNum[2]\n",
    "            #to handle values approcing to zero i.e. like  1.1e-16\n",
    "            if ig<=0.00000001:\n",
    "                values,count=np.unique(filteredData[targetAttr],return_counts=True)\n",
    "                return values[np.argmax(count)]\n",
    "            node={bestF:{}}\n",
    "            parent_node_class = np.unique(filteredData[target])[np.argmax(np.unique(filteredData[target],return_counts=True)[1])]\n",
    "            node[bestF][(split,True)]=buildTree(filteredData.where(filteredData[bestF]<=split).dropna(),odata,cFeatures,parent_node_class)\n",
    "            node[bestF][(split,False)]=buildTree(filteredData.where(filteredData[bestF]>split).dropna(),odata,cFeatures,parent_node_class)\n",
    "            return node;\n",
    "    else:\n",
    "        bestFCate=bestInfoGainFeature(filteredData,cFeatures, entropy)\n",
    "        bestFNum=bestInfoGainFeNumeric(filteredData, entropy)\n",
    "        parent_node_class = np.unique(filteredData[target])[np.argmax(np.unique(filteredData[target],return_counts=True)[1])]\n",
    "        \n",
    "        #if infromation gain of categorical attribute >= infromation gain of contineous/numerical attribute\n",
    "        if bestFCate[1]>=bestFNum[2]:\n",
    "            bestF=bestFCate[0]\n",
    "            node={bestF:{}}\n",
    "            cFeatures=[feature for feature in cFeatures if feature!=bestF]\n",
    "            for value in np.unique(filteredData[bestF]):\n",
    "                #filter new datatable based on best feature [value]\n",
    "                filteredData=filteredData.where(filteredData[bestF]==value).dropna()\n",
    "                node[bestF][value]=buildTree(filteredData,odata,cFeatures,parent_node_class)\n",
    "        else:\n",
    "            bestF=bestFNum[0]\n",
    "            split=bestFNum[1]\n",
    "            node={bestF:{}}\n",
    "            node[bestF][(split,True)]=buildTree(filteredData.where(filteredData[bestF]<=split).dropna(),odata,cFeatures,parent_node_class)\n",
    "            node[bestF][(split,False)]=buildTree(filteredData.where(filteredData[bestF]>split).dropna(),odata,cFeatures,parent_node_class)\n",
    "        \n",
    "    return node\n",
    "    \n",
    "# tree=buildTree(data,data,cFeatures)\n",
    "# print(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'satisfaction_level': {(0.46, True): {'number_project': {(2.0, True): {'last_evaluation': {(0.57, True): {'last_evaluation': {(0.44, True): 0.0, (0.44, False): {'average_montly_hours': {(161.0, True): {'average_montly_hours': {(125.0, True): 0.0, (125.0, False): {'satisfaction_level': {(0.31, True): {'Work_accident': {0.0: 0.0, 1.0: 0.0}}, (0.31, False): {'salary': {'high': {'sales': {'IT': 0.0, 'RandD': 1.0, 'accounting': 1.0, 'hr': 1.0, 'marketing': 1.0, 'product_mng': 1.0, 'sales': 1.0, 'support': 1.0, 'technical': 1.0}}, 'low': 1.0, 'medium': 1.0}}}}}}, (161.0, False): {'last_evaluation': {(0.54, True): {'average_montly_hours': {(219.0, True): 0.0, (219.0, False): {'sales': {'IT': 0.0, 'sales': 0.0, 'support': 0.0, 'technical': 0.0}}}}, (0.54, False): 1.0}}}}}}, (0.57, False): {'sales': {'IT': 0.0, 'RandD': 0.0, 'accounting': 0.0, 'hr': 0.0, 'management': 0.0, 'marketing': 0.0, 'product_mng': 0.0, 'sales': 0.0, 'support': 0.0, 'technical': 0.0}}}}, (2.0, False): {'satisfaction_level': {(0.11, True): 1.0, (0.11, False): {'number_project': {(6.0, True): {'average_montly_hours': {(287.0, True): {'sales': {'IT': {'satisfaction_level': {(0.14, True): {'salary': {'low': 0.0, 'medium': 0.0}}, (0.14, False): 0.0}}, 'RandD': 0.0, 'accounting': 0.0, 'hr': 0.0, 'management': 0.0, 'marketing': 0.0, 'product_mng': 0.0, 'sales': 0.0, 'support': 0.0, 'technical': 0.0}}, (287.0, False): 1.0}}, (6.0, False): 1.0}}}}}}, (0.46, False): {'time_spend_company': {(4.0, True): {'number_project': {(5.0, True): {'average_montly_hours': {(287.0, True): {'time_spend_company': {(3.0, True): {'number_project': {(2.0, True): {'average_montly_hours': {(167.0, True): 0.0, (167.0, False): {'sales': {'IT': {'average_montly_hours': {(273.0, True): 0.0, (273.0, False): 1.0}}, 'RandD': 0.0, 'accounting': 0.0, 'hr': 0.0, 'management': 0.0, 'marketing': 0.0, 'product_mng': 0.0, 'sales': 0.0, 'support': 0.0, 'technical': 0.0}}}}, (2.0, False): {'sales': {'IT': 0.0, 'RandD': 0.0, 'accounting': 0.0, 'hr': 0.0, 'management': 0.0, 'marketing': 0.0, 'product_mng': 0.0, 'sales': 0.0, 'support': 0.0, 'technical': 0.0}}}}, (3.0, False): {'sales': {'IT': 0.0, 'RandD': 0.0, 'accounting': 0.0, 'hr': 0.0, 'management': 0.0, 'marketing': 0.0, 'product_mng': 0.0, 'sales': 0.0, 'support': 0.0, 'technical': 0.0}}}}, (287.0, False): 1.0}}, (5.0, False): {'sales': {'IT': {'average_montly_hours': {(161.0, True): {'average_montly_hours': {(118.0, True): 0.0, (118.0, False): 1.0}}, (161.0, False): 0.0}}, 'RandD': 0.0, 'accounting': 0.0, 'hr': 0.0, 'management': 0.0, 'marketing': 0.0, 'product_mng': 0.0, 'sales': 0.0, 'support': 0.0, 'technical': 0.0}}}}, (4.0, False): {'last_evaluation': {(0.8, True): {'sales': {'IT': {'average_montly_hours': {(166.0, True): {'average_montly_hours': {(163.0, True): {'last_evaluation': {(0.73, True): 0.0, (0.73, False): 1.0}}, (163.0, False): 1.0}}, (166.0, False): 0.0}}, 'RandD': 0.0, 'accounting': 0.0, 'hr': 0.0, 'management': 0.0, 'marketing': 0.0, 'product_mng': 0.0, 'sales': 0.0, 'support': 0.0, 'technical': 0.0}}, (0.8, False): {'average_montly_hours': {(216.0, True): {'time_spend_company': {(5.0, True): {'number_project': {(3.0, True): {'average_montly_hours': {(126.0, True): 0.0, (126.0, False): {'salary': {'low': {'sales': {'hr': 1.0, 'product_mng': 1.0, 'sales': 1.0, 'support': 1.0, 'technical': 1.0}}, 'medium': 1.0}}}}, (3.0, False): 0.0}}, (5.0, False): {'last_evaluation': {(0.99, True): {'number_project': {(5.0, True): 0.0, (5.0, False): {'sales': {'accounting': 0.0, 'product_mng': 0.0, 'sales': 0.0, 'support': 0.0, 'technical': 0.0}}}}, (0.99, False): 1.0}}}}, (216.0, False): {'time_spend_company': {(6.0, True): {'satisfaction_level': {(0.71, True): {'last_evaluation': {(0.91, True): {'sales': {'IT': 0.0, 'RandD': 0.0, 'accounting': 0.0, 'management': 0.0, 'marketing': 0.0, 'product_mng': 0.0, 'sales': 0.0, 'support': 0.0, 'technical': 0.0}}, (0.91, False): {'sales': {'IT': 0.0, 'RandD': 0.0, 'marketing': 0.0, 'product_mng': 0.0, 'sales': 0.0, 'technical': 0.0}}}}, (0.71, False): {'number_project': {(3.0, True): {'average_montly_hours': {(286.0, True): 0.0, (286.0, False): 1.0}}, (3.0, False): {'number_project': {(5.0, True): {'satisfaction_level': {(0.92, True): {'sales': {'IT': 1.0, 'RandD': 1.0, 'accounting': 1.0, 'hr': 1.0, 'management': 1.0, 'marketing': 1.0, 'product_mng': 1.0, 'sales': 1.0, 'support': 1.0, 'technical': 1.0}}, (0.92, False): 0.0}}, (5.0, False): 0.0}}}}}}, (6.0, False): 0.0}}}}}}}}}}\n"
     ]
    }
   ],
   "source": [
    "totalDataSets=len(data)\n",
    "trainDataPercent=90\n",
    "trainDataSetCount=int(trainDataPercent*totalDataSets/100)\n",
    "\n",
    "trainData=data[:trainDataSetCount]\n",
    "# validateData=trainData\n",
    "validateData=data[trainDataSetCount:]\n",
    "# tree=buildTree1(trainData,cFeatures)\n",
    "tree=buildTree(trainData,trainData,cFeatures)\n",
    "print(tree)\n",
    "# print(\"finish\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74.91103202846975\n"
     ]
    }
   ],
   "source": [
    "def predictClassCategorical(tree,validateDataRow):\n",
    "    dataCols=validateDataRow.keys()\n",
    "    for key in dataCols:\n",
    "        if key in tree.keys():\n",
    "            try:\n",
    "                temp=tree[key][validateDataRow[key]]\n",
    "            except:\n",
    "                return 0\n",
    "            if isinstance(temp,dict):\n",
    "                return predictClassCategorical(temp,validateDataRow)\n",
    "            else:\n",
    "                return temp   \n",
    "count=0\n",
    "validateData1=validateData.to_dict(orient = \"records\")\n",
    "for i in range(len(validateData1)):\n",
    "    if validateData.iloc[i][keyValueMap[\"left\"]]==predictClassCategorical(tree,validateData1[i]):\n",
    "        count+=1\n",
    "print(count*100/len(validateData))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1124 24\n",
      "97.86476868327402\n"
     ]
    }
   ],
   "source": [
    "def predictClassNumerical(tree,validateDataRow):\n",
    "    dataCols=validateDataRow.keys()\n",
    "    for key in dataCols:\n",
    "        if key in tree.keys():\n",
    "            try:\n",
    "                temp=tree[key]\n",
    "                val=validateDataRow[key]\n",
    "                temp2=list(temp.keys())\n",
    "                if(isinstance(temp2[0],tuple)):\n",
    "                    if val<=temp2[0][0]:\n",
    "                        if isinstance(temp[temp2[0]],dict):\n",
    "                            return predictClassNumerical(temp[temp2[0]],validateDataRow)\n",
    "                        else:\n",
    "                            return temp[temp2[0]]\n",
    "                    else:\n",
    "                        if isinstance(temp[temp2[1]],dict):\n",
    "                            return predictClassNumerical(temp[temp2[1]],validateDataRow)\n",
    "                        else:\n",
    "                            return temp[temp2[1]]\n",
    "                else:\n",
    "                    if isinstance(temp[val],dict):\n",
    "                        return predictClassNumerical(temp[val],validateDataRow)\n",
    "                    else:\n",
    "                        return temp[val]\n",
    "            except:\n",
    "                return 0\n",
    "\n",
    "validateData1=validateData.to_dict(orient = \"records\")\n",
    "# print(predictClassNumerical(tree,validateData1[2]))\n",
    "count=0\n",
    "validateData1=validateData.to_dict(orient = \"records\")\n",
    "for i in range(len(validateData1)):\n",
    "    if validateData.iloc[i][keyValueMap[\"left\"]]==predictClassNumerical(tree,validateData1[i]):\n",
    "        count+=1\n",
    "print(len(validateData),len(validateData)-count)\n",
    "print(count*100/len(validateData))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
