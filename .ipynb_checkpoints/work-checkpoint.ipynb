{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Index:\n",
    "* **[Configure Attributes](#section0)**\n",
    "* **[Training and Prediction (Categorical) ](#section22)**\n",
    "* **[Training and Prediction (Numerical) ](#section32)**\n",
    "\n",
    "\n",
    "* [Utility functions common for both part](#section1)\n",
    "* [Part-1 : Training on catergorical data](#section2)\n",
    "    - [Algorithm](#section21)\n",
    "    - [Training and Prediction](#section22)\n",
    "* [Part-2: Training with categorical and numerical features.](#section3)\n",
    "    - [Algorithm](#section31)\n",
    "    - [Training and Prediction](#section32)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a style=\"text-decoration:none;color:#000\" id=\"section0\">Configure Attributes</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Provide the column names of categorical attributes\n",
    "cFeatures=['Work_accident','promotion_last_5years','sales','salary']\n",
    "\n",
    "#Provide the column names of numerical attributes\n",
    "nFeatures=['satisfaction_level','last_evaluation','number_project','average_montly_hours','time_spend_company']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a style=\"text-decoration:none;color:#000\" id=\"section1\">Utility functions common for both part</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import necessary packages\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to calculate intrinsic value\n",
    "def intrinsicCal(q):\n",
    "    if q :\n",
    "        return -q*np.log2(q)\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#function to calculate entropy i.e. -(qlogq+(1-q)log(1-q))\n",
    "def entropy(q) :\n",
    "    if q >= 1 or q <= 0:\n",
    "        return 0\n",
    "    return -( q*np.log2(q) + (1-q)*np.log2(1-q) )\n",
    "entropy(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to calculate Gini value i.e. 2q(1-q)\n",
    "def gini(q) :\n",
    "    return 2*q*(1-q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to calculate Misclassification rate i.e. min(q,1-q)\n",
    "def misClass(q) :\n",
    "    return min(q,1-q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Function to calculate information gain\n",
    "#Parameters :\n",
    "    # data = Training Data\n",
    "    # currentAttr = Categorical Attribute on which information Gain is calculated\n",
    "    # impType = Impurity type (entropy | gini | misClass) used to calculate information gain\n",
    "    # targetAttr = Target Attribute (Class Label) default is \"left\" column\n",
    "#Return :\n",
    "    # Return the information gain of current Attribute with impurity type(entrop/gini/misclass) relative to target attribute\n",
    "    \n",
    "def infoGain(data,currentAttr,impType,targetAttr=\"left\") :\n",
    "    \n",
    "    totalRows = data.shape[0] #total Rows in data\n",
    "    \n",
    "    #Class label unique values [0,1] and their corresponding counts [x,y]\n",
    "    targetValues, targetValuesCount = np.unique(data[targetAttr],return_counts=True)\n",
    "    \n",
    "    #Current Attribute unique values ex. [\"low\",\"medium\",\"high\"] and their corresponding counts [x,y,z]\n",
    "    currentValues, currentValuesCount = np.unique(data[currentAttr],return_counts=True)\n",
    "    \n",
    "    targetEntropy = impType(targetValuesCount[0]/(totalRows)) #target Entropy\n",
    "    \n",
    "    weightedEntropy = 0\n",
    "    intrinsic = 0\n",
    "    \n",
    "    data1 = data.values\n",
    "    valueMap = { j:0 for j in currentValues} #ex . {\"low\":0, \"medium\":0, \"high\":0}\n",
    "    \n",
    "    i=0\n",
    "    while(i < totalRows):\n",
    "        if data1[i][keyValueMap[targetAttr]] == 0:\n",
    "            valueMap[data1[i][keyValueMap[currentAttr]]] += 1\n",
    "        i += 1\n",
    "        \n",
    "    # summation (Si/S)*(entropy(left(=0)/Si)),(Sj/S)*(entropy(left(=0)/Sj)),.......\n",
    "    for j,i in enumerate(currentValues):\n",
    "        weightedEntropy += ( (currentValuesCount[j]/totalRows) * impType(valueMap[i]/currentValuesCount[j]) )\n",
    "        intrinsic += intrinsicCal(currentValuesCount[j]/totalRows)\n",
    "        \n",
    "    informationGain = targetEntropy - weightedEntropy\n",
    "    return informationGain#/intrinsic\n",
    "\n",
    "# print(infoGain(data,'salary',entropy))\n",
    "# print(infoGain(data,'promotion_last_5years',entropy))\n",
    "# print(infoGain(data,'Work_accident',entropy))\n",
    "# print(np.max([infoGain(data,feature,entropy) for feature in cFeatures]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Function return best atrribute (having maximum information gain) with its information gain\n",
    "#Parameters :\n",
    "    # data = Training Data\n",
    "    # cFeatures = Categorical Attributes list\n",
    "    # impType = Impurity type (entropy | gini | misClass) used to calculate information gain\n",
    "    \n",
    "#Return :\n",
    "    # Tuple (best Attribute, Information gain)\n",
    "\n",
    "def bestInfoGainFeature(data,cFeatures,impType):\n",
    "    infGains = [infoGain(data,feature,impType) for feature in cFeatures]\n",
    "    featureIndex = np.argmax(infGains)\n",
    "    bestFeature = cFeatures[featureIndex]\n",
    "    return (bestFeature,infGains[featureIndex])\n",
    "\n",
    "# bestInfoGainFeature(data,cFeatures,entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function return best split (having maximum information gain) for atrribute having contineous values\n",
    "\n",
    "#Parameters :\n",
    "    # data = Training Data\n",
    "    # currentAttr = Attribute (contineous value) on which information Gain is calculated\n",
    "    # impType = Impurity type (entropy | gini | misClass) used to calculate information gain\n",
    "    # targetAttr = Target Attribute (Class Label) default is \"left\" column\n",
    "#Return :\n",
    "    # Tuple (best split value, Information gain)\n",
    "\n",
    "def numericSplitInfoGain(data,currentAttr, impType,target=\"left\"):\n",
    "    totalRows = data.shape[0]\n",
    "    \n",
    "    #sort data on numerical attribute\n",
    "    data = data.sort_values(by=currentAttr, ascending=True, inplace=False)\n",
    "    \n",
    "    data1 = data.values;\n",
    "    ones  = np.sum(data[target]) #count of left=1 in data\n",
    "    zeros = totalRows-ones #count of left=0 in data\n",
    "    \n",
    "    targetEntropy=impType(ones/(totalRows))\n",
    "    \n",
    "    lableCountsForLess=[0,0]\n",
    "    labelCountsForGreater=[0,0]\n",
    "    \n",
    "    bestSplit = 0\n",
    "    mxInfoGain = -1\n",
    "    i = 0\n",
    "    currentIndex = keyValueMap[currentAttr]  #index of current Attribute\n",
    "    targetIndex = keyValueMap[target]   #index of target Attribute\n",
    "    while i < totalRows:\n",
    "        numericValue = data1[i][currentIndex]\n",
    "        checkClass = data1[i][targetIndex]\n",
    "        if checkClass == 0:\n",
    "            #count of target's zeros for currentAttr <= numericaval\n",
    "            lableCountsForLess[0] += 1\n",
    "        else:\n",
    "            #count of target's ones for currentAttr <= numericaval\n",
    "            lableCountsForLess[1] += 1\n",
    "        \n",
    "        #count of target's zeros for currentAttr > numericaval\n",
    "        labelCountsForGreater[0] = zeros - lableCountsForLess[0]\n",
    "        #count of target's ones for currentAttr > numericaval\n",
    "        labelCountsForGreater[1] = ones - lableCountsForLess[1]\n",
    "        \n",
    "        if( i+1 != totalRows and data1[i+1][currentIndex] == numericValue):\n",
    "            i += 1\n",
    "            continue\n",
    "\n",
    "        #count of datasets with currentAttr <= numeric\n",
    "        recordsLessThanNumeric = np.sum(lableCountsForLess)\n",
    "        #count of datasets with currentAttr > numeric\n",
    "        recordsGreaterThanNumeric = np.sum(labelCountsForGreater)\n",
    "        \n",
    "        a=0\n",
    "        b=0\n",
    "        intrinsic=0\n",
    "\n",
    "        if recordsLessThanNumeric:\n",
    "            a = (recordsLessThanNumeric/totalRows) * impType(lableCountsForLess[0]/recordsLessThanNumeric)\n",
    "            intrinsic += intrinsicCal(recordsLessThanNumeric/totalRows)\n",
    "        if recordsGreaterThanNumeric:\n",
    "            b = (recordsGreaterThanNumeric/totalRows)*impType(labelCountsForGreater[0]/recordsGreaterThanNumeric)\n",
    "            intrinsic += intrinsicCal(recordsGreaterThanNumeric/totalRows)\n",
    "        \n",
    "        weightedEntropy = a+b\n",
    "        informationGain = (targetEntropy-weightedEntropy)\n",
    "        \n",
    "        if(informationGain >= mxInfoGain):\n",
    "            mxInfoGain = informationGain\n",
    "            bestSplit = numericValue\n",
    "        i += 1\n",
    "    return (bestSplit,mxInfoGain)\n",
    "# numericSplitInfoGain(data,nFeatures[0],entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function return best atrribute (amongst all attributes with contineous values) \n",
    "# having maximum information gain\n",
    "#Parameters :\n",
    "    # data = Training Data\n",
    "    # impType = Impurity type (entropy | gini | misClass) used to calculate information gain\n",
    "#Return :\n",
    "    # Tuple (best Attribute, best split, Information gain)\n",
    "    \n",
    "def bestInfoGainFeNumeric(data,impType):\n",
    "    mxinFo = 0\n",
    "    split = 0\n",
    "    resF = \"\"\n",
    "    for feature in nFeatures:\n",
    "        fInfoG = numericSplitInfoGain(data,feature,impType)\n",
    "        if fInfoG[1] >= mxinFo:\n",
    "            resF = feature\n",
    "            split = fInfoG[0]\n",
    "            mxinFo = fInfoG[1]\n",
    "    return (resF,split,mxinFo)\n",
    "# bestInfoGainFeNumeric(data,entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read csv\n",
    "# target='left'\n",
    "def config(trainFile,trainDataPercent,testFile=None):\n",
    "    testData=None\n",
    "    global isValidateData\n",
    "    isValidateData=True\n",
    "    try:\n",
    "        data=pd.read_csv(trainFile)\n",
    "        try:\n",
    "            if testFile:\n",
    "                testData=pd.read_csv(testFile)\n",
    "                isValidateData=False\n",
    "        except:\n",
    "            print(\"Error reading test data\")\n",
    "            return False\n",
    "    except:\n",
    "        print(\"Error reading training data\")\n",
    "        return False\n",
    "    \n",
    "    global keyValueMap\n",
    "    keyValueMap={ j:i for i,j in enumerate(list(data.columns.values))}\n",
    "    totalDataSets=len(data)\n",
    "#     trainDataPercent=90\n",
    "    trainDataSetCount=int(trainDataPercent*totalDataSets/100)\n",
    "    \n",
    "    global trainData\n",
    "    trainData=data[:trainDataSetCount]\n",
    "    \n",
    "    global validateData\n",
    "    if isValidateData:\n",
    "        validateData=data[trainDataSetCount:]\n",
    "    else:\n",
    "        isValidateData=False\n",
    "        validateData=testData\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(tree,dType,targetAttr=\"left\"):\n",
    "    if len(validateData)==0:\n",
    "        print(\"No test/validate data found\")\n",
    "        return\n",
    "\n",
    "    if dType==\"categorical\":\n",
    "        dType=predictClassCategorical\n",
    "    elif dType== \"numerical\":\n",
    "        dType=predictClassNumerical\n",
    "    else:\n",
    "        print(\"Wrong Parameter\",dType)\n",
    "        return\n",
    "        \n",
    "    validateData1=validateData.to_dict(orient = \"records\")\n",
    "    \n",
    "    if isValidateData:\n",
    "        count=0\n",
    "        TP=0\n",
    "        TN=0\n",
    "        keyVMapVali={ j:i for i,j in enumerate(list(validateData.columns.values))}\n",
    "        \n",
    "        totalRows=len(validateData)\n",
    "        totalN=np.sum(validateData[targetAttr])\n",
    "        totalP=totalRows-totalN\n",
    "        \n",
    "        for i in range(len(validateData1)):\n",
    "            known=validateData.iloc[i][keyVMapVali[targetAttr]]\n",
    "            pred=dType(tree,validateData1[i])\n",
    "            if known==pred:\n",
    "                if known==0:\n",
    "                    TP+=1\n",
    "                else:\n",
    "                    TN+=1\n",
    "        FN=totalP-TP\n",
    "        FP=totalN-TN\n",
    "        print(totalRows,totalRows-(TP+TN))\n",
    "#         print(TP,TN,FP,FN)\n",
    "        recall=TP/(TP+FN)\n",
    "        precision=TP/(TP+FP)\n",
    "        accuracy=(TP+TN)/(totalRows)\n",
    "        f1Val=2*recall*precision/(recall+precision)\n",
    "        print(\"recall= \", recall)\n",
    "        print(\"precision= \", precision)\n",
    "        print(\"accuracy \",accuracy)\n",
    "        print(\"F1-Score \",f1Val)\n",
    "    else:\n",
    "        validateData.loc[:,'predicted'] = pd.Series()\n",
    "        predCol=validateData.columns.get_loc('predicted')\n",
    "        for i in range(len(validateData1)):\n",
    "            validateData.iloc[i,predCol] = dType(tree,validateData1[i])\n",
    "        print(\"Class predicted successfully: check output.csv\")\n",
    "        validateData\n",
    "        validateData.to_csv(\"output.csv\")\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a style=\"text-decoration:none;color:#000\" id=\"section2\">Part-1 : Training on catergorical data</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a style=\"text-decoration:none;color:#000\" id=\"section21\">-Algorithm</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Function train the decision tree on taking attributes as categorical and return the tree node\n",
    "#Parameters :\n",
    "    # filterdData = train data which keeps on filtering according to algorithm.\n",
    "    # cFeatures = list of catergorical attributes on which tree will be trained\n",
    "    # impType = Impurity type (entropy | gini | misClass) used to calculate information gain\n",
    "    # targetAttr = Target Attribute (Class Label) default is \"left\" column\n",
    "#Return :\n",
    "    # root node of tree\n",
    "\n",
    "def buildTreeCategorical(filterdData,cFeatures,impType,targetAttr=\"left\"):\n",
    "    \n",
    "    #check if data is pure i.e all tuples have exact 1 type of label\n",
    "    if(len(np.unique(filterdData[targetAttr]))<=1):\n",
    "        return np.unique(filterdData[targetAttr])[0]\n",
    "    \n",
    "    #check if all the categorical attributes had been used\n",
    "    elif(len(cFeatures)==0):\n",
    "        values,count=np.unique(filterdData[targetAttr],return_counts=True)\n",
    "        return values[np.argmax(count)]\n",
    "    \n",
    "    #else grow the tree for all possible value of best feature\n",
    "    #threby filtering the data on that value of best feature\n",
    "    else:\n",
    "        #find best feature\n",
    "        #create a node with best feature and return it at the end\n",
    "        #remove best feature from local list of features(cFeatures) for now\n",
    "        #execute a for loop for all possible value of best feature (filtering on this value), and create a branch on\n",
    "            #this value [best][value1] and receive the result of recursive call on this filtered data      \n",
    "        bestF=bestInfoGainFeature(filterdData,cFeatures, impType)[0]\n",
    "        node={bestF:{}}\n",
    "        cFeatures=[feature for feature in cFeatures if feature!=bestF]\n",
    "        for value in np.unique(filterdData[bestF]):\n",
    "            #filter new datatable based on best feature [value]\n",
    "            filteredData=filterdData.where(filterdData[bestF]==value).dropna()\n",
    "            node[bestF][value]=buildTreeCategorical(filteredData,cFeatures,impType)\n",
    "        \n",
    "    return node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def predictClassCategorical(tree,validateDataRow):\n",
    "    dataCols=validateDataRow.keys()\n",
    "    for key in dataCols:\n",
    "        if key in tree.keys():\n",
    "            try:\n",
    "                temp=tree[key][validateDataRow[key]]\n",
    "            except:\n",
    "                return 0\n",
    "            if isinstance(temp,dict):\n",
    "                return predictClassCategorical(temp,validateDataRow)\n",
    "            else:\n",
    "                return temp   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainAndTestCategorical(trainFile,trainDataPercent,impType,testFile=None):\n",
    "    if not(config(trainFile,trainDataPercent,testFile)):\n",
    "        return\n",
    "    tree=buildTreeCategorical(trainData,cFeatures,impType)\n",
    "    print(tree)\n",
    "    predict(tree,\"categorical\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a style=\"text-decoration:none;color:#000\" id=\"section22\">-Training and Prediction (Categorical) </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'salary': {'high': {'sales': {'IT': {'Work_accident': {0.0: {'promotion_last_5years': {0.0: 0.0}}, 1.0: 0.0}}, 'RandD': {'Work_accident': {0.0: {'promotion_last_5years': {0.0: 0.0, 1.0: 0.0}}, 1.0: 0.0}}, 'accounting': {'Work_accident': {0.0: {'promotion_last_5years': {0.0: 0.0, 1.0: 0.0}}, 1.0: 0.0}}, 'hr': {'Work_accident': {0.0: {'promotion_last_5years': {0.0: 0.0, 1.0: 0.0}}, 1.0: 0.0}}, 'management': {'promotion_last_5years': {0.0: {'Work_accident': {0.0: 0.0, 1.0: 0.0}}, 1.0: 0.0}}, 'marketing': {'Work_accident': {0.0: {'promotion_last_5years': {0.0: 0.0}}, 1.0: 0.0}}, 'product_mng': {'Work_accident': {0.0: {'promotion_last_5years': {0.0: 0.0}}, 1.0: 0.0}}, 'sales': {'Work_accident': {0.0: {'promotion_last_5years': {0.0: 0.0, 1.0: 0.0}}, 1.0: 0.0}}, 'support': {'Work_accident': {0.0: {'promotion_last_5years': {0.0: 0.0}}, 1.0: 0.0}}, 'technical': {'Work_accident': {0.0: {'promotion_last_5years': {0.0: 0.0}}, 1.0: 0.0}}}}, 'low': {'Work_accident': {0.0: {'sales': {'IT': {'promotion_last_5years': {0.0: 0.0, 1.0: 1.0}}, 'RandD': {'promotion_last_5years': {0.0: 0.0, 1.0: 0.0}}, 'accounting': {'promotion_last_5years': {0.0: 0.0, 1.0: 0.0}}, 'hr': {'promotion_last_5years': {0.0: 0.0, 1.0: 0.0}}, 'management': {'promotion_last_5years': {0.0: 0.0, 1.0: 1.0}}, 'marketing': {'promotion_last_5years': {0.0: 0.0, 1.0: 0.0}}, 'product_mng': {'promotion_last_5years': {0.0: 0.0}}, 'sales': {'promotion_last_5years': {0.0: 0.0, 1.0: 0.0}}, 'support': {'promotion_last_5years': {0.0: 0.0, 1.0: 0.0}}, 'technical': {'promotion_last_5years': {0.0: 0.0, 1.0: 0.0}}}}, 1.0: {'sales': {'IT': {'promotion_last_5years': {0.0: 0.0}}, 'RandD': {'promotion_last_5years': {0.0: 0.0, 1.0: 0.0}}, 'accounting': {'promotion_last_5years': {0.0: 0.0}}, 'hr': {'promotion_last_5years': {0.0: 0.0}}, 'management': {'promotion_last_5years': {0.0: 0.0, 1.0: 0.0}}, 'marketing': {'promotion_last_5years': {0.0: 0.0, 1.0: 0.0}}, 'product_mng': {'promotion_last_5years': {0.0: 0.0}}, 'sales': {'promotion_last_5years': {0.0: 0.0, 1.0: 1.0}}, 'support': {'promotion_last_5years': {0.0: 0.0}}, 'technical': {'promotion_last_5years': {0.0: 0.0, 1.0: 0.0}}}}}}, 'medium': {'Work_accident': {0.0: {'sales': {'IT': {'promotion_last_5years': {0.0: 0.0, 1.0: 1.0}}, 'RandD': {'promotion_last_5years': {0.0: 0.0, 1.0: 0.0}}, 'accounting': {'promotion_last_5years': {0.0: 0.0, 1.0: 0.0}}, 'hr': {'promotion_last_5years': {0.0: 0.0, 1.0: 0.0}}, 'management': {'promotion_last_5years': {0.0: 0.0, 1.0: 0.0}}, 'marketing': {'promotion_last_5years': {0.0: 0.0, 1.0: 0.0}}, 'product_mng': {'promotion_last_5years': {0.0: 0.0}}, 'sales': {'promotion_last_5years': {0.0: 0.0, 1.0: 0.0}}, 'support': {'promotion_last_5years': {0.0: 0.0, 1.0: 0.0}}, 'technical': {'promotion_last_5years': {0.0: 0.0, 1.0: 0.0}}}}, 1.0: {'sales': {'IT': {'promotion_last_5years': {0.0: 0.0}}, 'RandD': {'promotion_last_5years': {0.0: 0.0, 1.0: 0.0}}, 'accounting': {'promotion_last_5years': {0.0: 0.0}}, 'hr': {'promotion_last_5years': {0.0: 0.0, 1.0: 0.0}}, 'management': {'promotion_last_5years': {0.0: 0.0, 1.0: 0.0}}, 'marketing': {'promotion_last_5years': {0.0: 0.0, 1.0: 0.0}}, 'product_mng': {'promotion_last_5years': {0.0: 0.0}}, 'sales': {'promotion_last_5years': {0.0: 0.0, 1.0: 0.0}}, 'support': {'promotion_last_5years': {0.0: 0.0, 1.0: 0.0}}, 'technical': {'promotion_last_5years': {0.0: 0.0, 1.0: 0.0}}}}}}}}\n",
      "1124 282\n",
      "recall=  1.0\n",
      "precision=  0.748886910062333\n",
      "accuracy  0.7491103202846975\n",
      "F1-Score  0.8564154786150713\n"
     ]
    }
   ],
   "source": [
    "trainAndTestCategorical(\"train.csv\",90,entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a style=\"text-decoration:none;color:#000\" id=\"section3\">Part-2: Training with categorical and numerical features.</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a style=\"text-decoration:none;color:#000\" id=\"section31\">-Algorithm</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Function train the decision tree with categorical and numerical features  and return the tree node\n",
    "#Parameters :\n",
    "    # filterdData = train data which keeps on filtering according to algorithm.\n",
    "    # cFeatures = list of catergorical attributes (unused categorical features)\n",
    "    # impType = Impurity type (entropy | gini | misClass) used to calculate information gain\n",
    "    # targetAttr = Target Attribute (Class Label) default is \"left\" column\n",
    "    # Note: uses nFeatures i.e numerical features in utility methods\n",
    "#Return :\n",
    "    # root node of tree\n",
    "\n",
    "def buildTreeCatAndNum(filteredData,cFeatures,impType,parentDataMode=None,targetAttr=\"left\"):\n",
    "    \n",
    "    # check if data is empty, if so, return the class of target i.e \"left\" appeared maximum in its parent data\n",
    "    if len(filteredData)==0:\n",
    "        return parentDataMode\n",
    "    \n",
    "    # check if data is pure i.e all tuples have exact 1 type of label, if so return it\n",
    "    if(len(np.unique(filteredData[targetAttr]))==1):\n",
    "        return np.unique(filteredData[targetAttr])[0]\n",
    "    \n",
    "    # check if all the categorical attributes had been used, (numerical split may be possible)\n",
    "    elif(len(cFeatures)==0):\n",
    "    \n",
    "            # best numerical Feature and its split value\n",
    "            bestFNum=bestInfoGainFeNumeric(filteredData, impType)\n",
    "            bestF=bestFNum[0] # best Feature\n",
    "            split=bestFNum[1] # split value\n",
    "            ig=bestFNum[2]    # information gain\n",
    "            \n",
    "            # to handle values approcing to zero i.e. like  1.1e-16\n",
    "            if ig<=0.00000001:\n",
    "                values,count=np.unique(filteredData[targetAttr],return_counts=True)\n",
    "                return values[np.argmax(count)]\n",
    "            \n",
    "            node={bestF:{}}\n",
    "            parentDataMode = np.unique(filteredData[targetAttr])[np.argmax(np.unique(filteredData[targetAttr],return_counts=True)[1])]\n",
    "            node[bestF][(split,True)]=buildTreeCatAndNum(filteredData.where(filteredData[bestF]<=split).dropna(),cFeatures,impType,parentDataMode)\n",
    "            node[bestF][(split,False)]=buildTreeCatAndNum(filteredData.where(filteredData[bestF]>split).dropna(),cFeatures,impType,parentDataMode)\n",
    "            return node;\n",
    "\n",
    "    # if not all categorical attributes had been used\n",
    "    else:\n",
    "\n",
    "        # get best categorical attribute and its info gain\n",
    "        bestFCate=bestInfoGainFeature(filteredData,cFeatures, impType)\n",
    "       \n",
    "        # get best numerical attribute and its info gain\n",
    "        bestFNum=bestInfoGainFeNumeric(filteredData, impType)\n",
    "        \n",
    "        # target i.e \"left\" class appeared maximum number of times\n",
    "        parentDataMode = np.unique(filteredData[targetAttr])[np.argmax(np.unique(filteredData[targetAttr],return_counts=True)[1])]\n",
    "        \n",
    "        ig=max(bestFCate[1],bestFNum[2])\n",
    "        \n",
    "        # to handle values approcing to zero i.e. like  1.1e-16\n",
    "        if ig<=0.00000001:\n",
    "            values,count=np.unique(filteredData[targetAttr],return_counts=True)\n",
    "            return values[np.argmax(count)]\n",
    "        \n",
    "        # if infromation gain of categorical attribute >= infromation gain of numerical attribute\n",
    "        if bestFCate[1]>=bestFNum[2]:\n",
    "            bestF=bestFCate[0]\n",
    "            node={bestF:{}}\n",
    "            cFeatures=[feature for feature in cFeatures if feature!=bestF]\n",
    "            for value in np.unique(filteredData[bestF]):\n",
    "                # filter data based on best feature [value] and create a branch on it\n",
    "                # here branch is identified by direct value\n",
    "                filteredData=filteredData.where(filteredData[bestF]==value).dropna()\n",
    "                node[bestF][value]=buildTreeCatAndNum(filteredData,cFeatures,impType,parentDataMode)\n",
    "        else:\n",
    "            bestF=bestFNum[0]\n",
    "            split=bestFNum[1]\n",
    "            node={bestF:{}}\n",
    "            # create 2 branches on split value (<= and >) and filter data accordingly\n",
    "            # here branch is identified by tuple\n",
    "            node[bestF][(split,True)]=buildTreeCatAndNum(filteredData.where(filteredData[bestF]<=split).dropna(),cFeatures,impType,parentDataMode)\n",
    "            node[bestF][(split,False)]=buildTreeCatAndNum(filteredData.where(filteredData[bestF]>split).dropna(),cFeatures,impType,parentDataMode)\n",
    "        \n",
    "    return node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictClassNumerical(tree,validateDataRow):\n",
    "    dataCols=validateDataRow.keys()\n",
    "    for key in dataCols:\n",
    "        if key in tree.keys():            \n",
    "#             try:\n",
    "            temp=tree[key]\n",
    "            val=validateDataRow[key]\n",
    "            temp2=list(temp.keys())\n",
    "            if(isinstance(temp2[0],tuple)):\n",
    "                if val<=temp2[0][0]:\n",
    "                    if isinstance(temp[temp2[0]],dict):\n",
    "                        return predictClassNumerical(temp[temp2[0]],validateDataRow)\n",
    "                    else:\n",
    "                        return temp[temp2[0]]\n",
    "                else:\n",
    "                    if isinstance(temp[temp2[1]],dict):\n",
    "                        return predictClassNumerical(temp[temp2[1]],validateDataRow)\n",
    "                    else:\n",
    "                        return temp[temp2[1]]\n",
    "            else:\n",
    "                try:\n",
    "                    if isinstance(temp[val],dict):\n",
    "                        return predictClassNumerical(temp[val],validateDataRow)\n",
    "                    else:\n",
    "                        return temp[val]\n",
    "                except:\n",
    "                    return 0\n",
    "#             except:\n",
    "#                 return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainAndTestNumerical(trainFile,trainDataPercent,impType,testFile=None):\n",
    "    if not(config(trainFile,trainDataPercent,testFile)):\n",
    "        return\n",
    "    tree=buildTreeCatAndNum(trainData,cFeatures,impType)\n",
    "#     print(tree)\n",
    "    predict(tree,\"numerical\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a style=\"text-decoration:none;color:#000\" id=\"section32\">-Training and Prediction (Numerical)</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> You can pass following parameters in order\n",
    "\n",
    "> Param1     : Training Data file\n",
    "\n",
    "> Param2     : Training Data (percent to train on) Ex. 90 means TrainingData=90% and ValidationData=10% (remaining data)\n",
    "\n",
    "> Param3     : Impurity type, possible values: entropy , gini, misClass\n",
    "\n",
    "> Param4 (optional)  : testData file (if provided then it train data on percent provided and predict class for test data and create outpu.txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1124 24\n",
      "recall=  0.9964328180737217\n",
      "precision=  0.9755529685681025\n",
      "accuracy  0.9786476868327402\n",
      "F1-Score  0.9858823529411765\n"
     ]
    }
   ],
   "source": [
    "trainAndTestNumerical(\"train.csv\",90,entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'low'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-404-933238ad4103>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;31m#             plt.show()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0mads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-404-933238ad4103>\u001b[0m in \u001b[0;36mads\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mfeatures\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfeature\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mfeature\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0;34m\"left\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mlength\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx_0\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'salary'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0midx_0\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"number_project\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'g'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Not Left'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx_1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'salary'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0midx_1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"number_project\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Left'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m#     for i in range(length):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mscatter\u001b[0;34m(x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, verts, edgecolors, data, **kwargs)\u001b[0m\n\u001b[1;32m   2862\u001b[0m         \u001b[0mvmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvmin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvmax\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvmax\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlinewidths\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlinewidths\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2863\u001b[0m         verts=verts, edgecolors=edgecolors, **({\"data\": data} if data\n\u001b[0;32m-> 2864\u001b[0;31m         is not None else {}), **kwargs)\n\u001b[0m\u001b[1;32m   2865\u001b[0m     \u001b[0msci\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__ret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2866\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m__ret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1808\u001b[0m                         \u001b[0;34m\"the Matplotlib list!)\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlabel_namer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1809\u001b[0m                         RuntimeWarning, stacklevel=2)\n\u001b[0;32m-> 1810\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1811\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1812\u001b[0m         inner.__doc__ = _add_data_doc(inner.__doc__,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mscatter\u001b[0;34m(self, x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, verts, edgecolors, **kwargs)\u001b[0m\n\u001b[1;32m   4295\u001b[0m                 \u001b[0moffsets\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moffsets\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4296\u001b[0m                 \u001b[0mtransOffset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'transform'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransData\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4297\u001b[0;31m                 \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4298\u001b[0m                 )\n\u001b[1;32m   4299\u001b[0m         \u001b[0mcollection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIdentityTransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/matplotlib/collections.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, paths, sizes, **kwargs)\u001b[0m\n\u001b[1;32m    897\u001b[0m         \"\"\"\n\u001b[1;32m    898\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 899\u001b[0;31m         \u001b[0mCollection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    900\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_paths\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpaths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    901\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_sizes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/matplotlib/collections.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, edgecolors, facecolors, linewidths, linestyles, capstyle, joinstyle, antialiaseds, offsets, transOffset, norm, cmap, pickradius, hatch, urls, offset_position, zorder, **kwargs)\u001b[0m\n\u001b[1;32m    153\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_uniform_offsets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0moffsets\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m             \u001b[0moffsets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masanyarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moffsets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m             \u001b[0;31m# Broadcast (2,) -> (1, 2) but nothing else.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0moffsets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36masanyarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m    551\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m     \"\"\"\n\u001b[0;32m--> 553\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'low'"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.style\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams.update(mpl.rcParamsDefault)\n",
    "# mpl.style.use('Solarize_Light2')\n",
    "# from cycler import cycler\n",
    "# mpl.rcParams['axes.prop_cycle'] = cycler(color='crgbrcmyk')\n",
    "\n",
    "\n",
    "def ads():\n",
    "    data=pd.read_csv(\"train.csv\")\n",
    "    idx_1 = data.where(data[\"left\"] == 1)\n",
    "    idx_0 = data.where(data[\"left\"] == 0)\n",
    "    features=[feature for feature in data.columns.values if feature!=\"left\"]\n",
    "    length=len(features)\n",
    "    plt.scatter(idx_0['salary'],idx_0[\"number_project\"],s=30,c='g',label='Not Left')\n",
    "    plt.scatter(idx_1['salary'],idx_1[\"number_project\"],s=15,c='r',label='Left')\n",
    "#     for i in range(length):\n",
    "#         for j in range(i+1,length):\n",
    "#             plt.scatter(idx_0[features[i]],idx_0[features[j]],s=30,c='g',label='Not Left')\n",
    "#             plt.scatter(idx_1[features[i]],idx_1[features[j]],s=15,c='r',label='Left')\n",
    "#             plt.legend()\n",
    "#             plt.legend(loc=0)\n",
    "#             plt.xlabel(features[i])\n",
    "#             plt.ylabel(features[j])\n",
    "#             plt.show()\n",
    "\n",
    "ads()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
